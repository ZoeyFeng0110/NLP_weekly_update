import json
from zhipuai import ZhipuAI
from openai import OpenAI
from tqdm import tqdm
import os

# Load JSON file with posts
input_folder = "/Users/oliviafeng/Desktop/uchi/digitaltext1/final_project/divided_by_category/Uncategorized"
output_folder = "/Users/oliviafeng/Desktop/uchi/digitaltext1/final_project/divided_by_category/Uncategorized_done"
archive_folder = "/Users/oliviafeng/Desktop/uchi/digitaltext1/final_project/divided_by_category/archive_folder"

# ç¡®ä¿è¾“å‡ºå’Œå½’æ¡£æ–‡ä»¶å¤¹å­˜åœ¨
os.makedirs(output_folder, exist_ok=True)
os.makedirs(archive_folder, exist_ok=True)

# è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
import glob
json_files = glob.glob(os.path.join(input_folder, "*.json"))
print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")

# è·å–å·²å¤„ç†çš„æ–‡ä»¶åï¼ˆæ£€æŸ¥å½’æ¡£æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼‰
processed_files = set(os.path.basename(f) for f in glob.glob(os.path.join(archive_folder, "*.json")))
print(f"å·²å¤„ç†æ–‡ä»¶æ•°: {len(processed_files)}")

# åˆ›å»ºCSVè®°å½•æ–‡ä»¶
import csv
csv_file_path = os.path.join(output_folder, "categorization_results.csv")
if not os.path.exists(csv_file_path):
    with open(csv_file_path, mode="w", encoding="utf-8", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(["file_name", "note_id", "title", "category"])

# Define system message with task instructions
SYSTEM_PROMPT = """
You are a cross-cultural communication researcher analyzing social media posts on RedNote related to the recent migration of foreign TikTok users to the RedNote platform. Your task is to categorize each post into only one most relevant categories based on its post content.

### Categories:

1. Platform Migration & Adaptation
1a. About TikTok Ban / Censorship (e.g., posts discussing TikTok restrictions, bans, algorithm bias)
1b. About Adjusting to RedNote (e.g., comparisons between TikTok and RedNote, migration struggles)

2. Cross-Cultural Communication & Identity
2a. Music Sharing & Cultural Exchange (e.g., sharing songs from different cultures, music traditions)
2b. National Identity & Stereotypes (e.g., "How do Americans see China?" or cultural comparisons)
2c. Food & Lifestyle & Fashion comparison and sharing(e.g., cultural curiosity about foreign foods, daily life differences)
2d. Fan Culture & Celebrity Sharing (e.g., discussions about artists/celebrities from different cultures)


3. Political Discourse
3a. Political & Social Movements (e.g., BLM, climate change, Meta boycotts)
3b. Free Speech & Digital Rights (e.g., debates on censorship, privacy, surveillance)
3c. Digital Nationalism & Globalization (e.g., debates on Chinese vs. Western digital spaces)
3d. International Relations & Geopolitics

4. Marketing & E-Commerce
4a. Advertising Strategies
4b. Consumer Behavior & Trends
4c. Platform Monetization Debates

5. Creative Expression 
5a. Memes & Humor (e.g., internet humor, meme adaptation across platforms)
5b. Creative Hobbies & DIY & talent show (e.g., crafts, handmade items, creative projects, displaying personal artistic skills)

6. Social Interaction & Personal Narratives
6a. Self-Introduction & Personal Stories (e.g., pets, self-introduction posts, emotional reflections, daily life)
6b. Friendship & Community Building (e.g., posts seeking new friends on RedNote)
6c. Relationship Advice & Experiences
6d. Personal Growth & Life Reflections

7. Unknown / Not Relevant (If the post does not fit any of the above categories, you can mark it 7 and then name a new category, like "7: Other")
"""

# Function to generate user prompt with post data
def generate_user_prompt(post):
    # å¤„ç†commentså­—æ®µï¼Œç¡®ä¿å®ƒæ˜¯å­—ç¬¦ä¸²
    comments = post.get('comments', '')
    if isinstance(comments, list):
        comments = "\n".join(comments) if comments else ""
    
    return f"""
### Post to Categorize:
Title: {post.get('title', 'No Title')}
Description: {post.get('desc', 'No Description')}
Comments: {comments}
Tags: {post.get('tag_list', '')}
Engagement: {post.get('liked_count', 'Unknown')} likes

Return only one category labels, e.g., "1a".
"""

# Function to parse AI response
def parse_ai_response(response_text):
    try:
        response_text = response_text.strip()
        print(f"ğŸ”¹ Raw AI Response: {response_text}")  # Debugging print

        # å°è¯•æå–å•ä¸ªæ•°å­—ç±»åˆ«
        import re
        # category_match = re.search(r'[1-7]', response_text)
        category_match = re.search(r'([1-7][a-e]?)', response_text)
        if category_match:
            return {"category": category_match.group(0)}
        else:
            print("âš ï¸ No categories extracted.")
            return {"category": "error"}

    except Exception as e:
        print(f"âŒ Error parsing AI response: {e}")
        return {"category": "error"}

# æ‰¹å¤„ç†åŠŸèƒ½
def process_batch(client, model, batch_files, batch_size=10):
    csv_records = []
    processed_batch = []
    
    for file_path in tqdm(batch_files, desc=f"Processing batch of {len(batch_files)} files"):
        try:
            file_name = os.path.basename(file_path)
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if file_name in processed_files:
                continue
            
            # åŠ è½½JSONæ–‡ä»¶
            with open(file_path, "r", encoding="utf-8") as f:
                post = json.load(f)
            
            # è·å–å¸–å­ID
            note_id = post.get('note_id', '')
            title = post.get('title', '')
            
            print(f"Processing post: {note_id} - {title[:30]}...")
            user_prompt = generate_user_prompt(post)

            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]

            response = client.chat.completions.create(
                model=model,
                messages=messages
            )

            assistant_response = response.choices[0].message.content
            
            # è§£æå“åº”
            response_json = parse_ai_response(assistant_response)
            category = response_json.get("category", "error")
            
            # æ›´æ–°å¸–å­æ•°æ®
            post["category"] = category
            
            # ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹
            output_file_path = os.path.join(output_folder, file_name)
            with open(output_file_path, "w", encoding="utf-8") as f:
                json.dump(post, f, ensure_ascii=False, indent=4)
            
            # æ·»åŠ åˆ°CSVè®°å½•
            csv_records.append([file_name, note_id, title, category])
            
            # æ·»åŠ åˆ°å·²å¤„ç†æ‰¹æ¬¡
            processed_batch.append((file_path, archive_folder))
            
        except Exception as e:
            print(f"Error processing file {file_path}: {e}")
    
    # æ›´æ–°CSVæ–‡ä»¶
    with open(csv_file_path, mode="a", encoding="utf-8", newline="") as file:
        writer = csv.writer(file)
        for record in csv_records:
            writer.writerow(record)
    
    # ç§»åŠ¨å·²å¤„ç†æ–‡ä»¶
    for source_file, dest_folder in processed_batch:
        file_name = os.path.basename(source_file)
        dest_path = os.path.join(dest_folder, file_name)
        try:
            import shutil
            shutil.copy2(source_file, dest_path)  # å¤åˆ¶åˆ°å½’æ¡£æ–‡ä»¶å¤¹
            os.remove(source_file)  # åˆ é™¤åŸå§‹æ–‡ä»¶
            processed_files.add(file_name)  # æ·»åŠ åˆ°å·²å¤„ç†é›†åˆ
        except Exception as e:
            print(f"æ–‡ä»¶ç§»åŠ¨å¤±è´¥ {file_name}: {e}")
    
    return len(processed_batch)

# ä¸»å¤„ç†å‡½æ•°
def call_ai(client, model, max_files=20000, batch_size=10):
    # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
    files_to_process = [f for f in json_files if os.path.basename(f) not in processed_files]
    
    if max_files:
        files_to_process = files_to_process[:max_files]
    
    print(f"éœ€è¦å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶")
    
    # åˆ†æ‰¹å¤„ç†
    total_processed = 0
    for i in range(0, len(files_to_process), batch_size):
        batch = files_to_process[i:i+batch_size]
        processed = process_batch(client, model, batch, batch_size)
        total_processed += processed
        print(f"å·²å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}ï¼Œæ€»å…±å¤„ç† {total_processed} ä¸ªæ–‡ä»¶")
    
    print(f"âœ… å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {total_processed} ä¸ªæ–‡ä»¶ï¼Œç»“æœä¿å­˜åˆ° {output_folder}")
    
    # ç”Ÿæˆç»Ÿè®¡æ•°æ®
    try:
        # è¯»å–ç»“æœCSV
        category_counts = {}
        with open(csv_file_path, "r", encoding="utf-8", newline="") as file:
            reader = csv.reader(file)
            next(reader)  # è·³è¿‡æ ‡é¢˜è¡Œ
            for row in reader:
                if len(row) >= 4:
                    category = row[3]
                    if category in category_counts:
                        category_counts[category] += 1
                    else:
                        category_counts[category] = 1
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        with open(os.path.join(output_folder, "category_summary.json"), "w", encoding="utf-8") as f:
            json.dump({
                "total_processed": total_processed,
                "category_distribution": category_counts
            }, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆå¤±è´¥: {e}")

# ä½¿ç”¨æ™ºè°±AIè¿›è¡Œåˆ†ç±»
client = ZhipuAI(api_key="72d38a74be1e3bb61c552a7e105cfce3.ix1koYYSjZO9w7f4")
call_ai(client, "glm-4-flash", max_files=20000, batch_size=10)

# å¦‚æœè¦æµ‹è¯•å…¶ä»–æ¨¡å‹ï¼Œå–æ¶ˆç›¸åº”çš„æ³¨é‡Š
"""
# deepseek-chat
client = OpenAI(
    api_key="sk-32c365525bef4c6a9f20dfeaa6dc1f8e",
    base_url="https://api.deepseek.com",
)
call_ai(client, "deepseek-chat", max_files=20000, batch_size=10)
"""